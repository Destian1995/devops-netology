# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

---

- __мониторинг операционной системы__:
  - процессор:
    - load average
  - память:
    - usage
  - диск:
    - объем данных
    - скорость записи/чтения
    - количество inodes
  - сеть:
    - загруженность интерфейсов
- __мониторинг задействованных сервисов (субд, веб-серверов, файловые хранилища)__:
  - доступность
  - загруженность
  - наличие ошибок
  - время отклика
- __мониторинг приложения__:
  - HTTP-запросы:
    - общее количество запросов
    - количество ошибочных запросов
    - время выполнения запросов
  - операции расчета и вывода данных:
    - количество операций
    - статус операций
    - время исполнения операций

---

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?

---

Нужно уточнить, какие обязательства фигурировали в договоре с клиентами, либо же какой уровень обслуживания декларировался. Затем привести собранные метрики к этим задекларированным индикаторам. Для описанной системы такими индикаторами могут быть:

- доступность системы в процентах;
- время выполнения запрошенной клиентом операции (минимальное, среднее и максимальное)
- допустимый процент ошибок

---

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

---

Ни одно серьезное решение не возможно без бюджета...
- сэкономить на системе логирования можно, если переложить эту задачу на бюджет разработки, заставив программистов переделать код так, чтобы он работал с Sentry и выдавал не только ошибку приложения, но и весь необходимый контекст из других связанных сервисов. 
- Можно также предложить систематизировать ошибки приложения, договорившись, чтобы приложение отдавало определенный error code при возникновении той или иной ошибки. Такой код можно превратить в метрику, и по крайней мере отслеживать количество тех или иных ошибок, а также аномалии в этой величине. Это решение подразумевает, что затраты DevOps ограничатся лишь добавлением некоторого количества новых правил в существующую систему сбора метрик, но тем не менее потребуются затраты на рефакторинг подсистемы логирования в приложении. 
- Можно предложить построить урезанную схему сбора логов. Например,
    - собирать только записи с severity:ERROR;
    - собирать ошибки только с минимального количества необходимых приложений;
    - собирать ошибки не со всех реплик запущенного приложения, а только с ограниченного набора;
    - хранить логи минимально необходимый период времени;
    - настроить алертинг и триггеры, которые бы срабатывали во время ошибки и собирали бы дополнительную информацию.
  Эта схема позволит отлавливать определенный процент ошибок, а также позволит масштабировать схему до полноценной, когда на это будут выделены ресурсы.

---

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

---

Нужно собрать информацию обо всех имеющихся в логах кодах ответов. Вероятнее всего 30% запросов завершаются с кодами 100-199 (informational) 
или кодами 300-399 (redirectional), в общем случае не являющимися ошибочными. Их нужно либо добавить в числитель выражения, либо вычесть из знаменателя.

---
5. Опишите основные плюсы и минусы pull и push систем мониторинга.

---
__push model__:

  __плюсы__:
  - не требует открытия входящих портов на агентах;
  - можно обеспечить высокую сетевую производительность, используя udp;
  - гибкая настройка агентов в части обмена трафиком.

  __минусы__:
  - полное отсутствие информации о состоянии агента, если он не присылает метрики;
  - сложнее контролировать подлинность данных;

__pull model__:

  __плюсы__:
  - есть возможность централизованно выбирать агенты, с которых требуется собирать метрики;
  - простой протокол сбора метрик, легко повторить вручную при дебаге;

  __минусы__:
  - требуется дополнительный механизм обновления списка объектов мониторинга (discovery);
  - необходимо открывать входящие порты на объектах мониторинга;
  - плохо ложится на событийную модель сбора метрик, например, для сбора результатов исполнения каких-то разовых задач;
---

6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

  - __Prometheus__: основным является pull; push лимитирован, требуется pushgateway
  - __TICK__: push или pull в зависимости от возможностей input плагина;
  - __Zabbix__: push или pull;
  - __VictoriaMetrics__: основным является pull через vmagent, но есть и возможность push с использованием remote write;
  - __Nagios__: основной pull и дополнительный push в зависимости от агента;

---

7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите выводы команд с вашего компьютера (виртуальной машины):

    - curl http://localhost:8086/ping
    - curl http://localhost:8888
    - curl http://localhost:9092/kapacitor/v1/ping
	
```
vagrant@vagrant:~/sandbox$ curl http://localhost:8086
```
```
vagrant@vagrant:~/sandbox$ curl http://localhost:8888
<!DOCTYPE html><html><head><link rel="stylesheet" href="/index.c708214f.css"><meta http-equiv="Content-type" 
content="text/html; charset=utf-8"><title>Chronograf</title><link rel="icon shortcut" href="/favicon.70d63073.ico"></head><body> <div id="react-root" data-basepath=""></div> <script type="module" src="/index.e81b88ee.js"></script><script src="/index.a6955a67.js" nomodule="" defer></script> </body></html>
```
```
curl http://localhost:9092/kapacitor/v1/ping
```

А также скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`

---





8. Перейдите в веб-интерфейс Chronograf (`http://localhost:8888`) и откройте вкладку `Data explorer`.

    - Нажмите на кнопку `Add a query`
    - Изучите вывод интерфейса и выберите БД `telegraf.autogen`
    - В `measurments` выберите mem->host->telegraf_container_id , а в `fields` выберите used_percent. 
    Внизу появится график утилизации оперативной памяти в контейнере telegraf.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. 
    Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации места на диске 
(disk->host->telegraf_container_id) из веб-интерфейса.

Так как данные метрики отсутствовали для их отображения я добавил в файл telegraf.conf
```
[[inputs.disk]]
[[inputs.mem]]
```
![2](https://user-images.githubusercontent.com/106807250/212663393-89632b39-f1ef-401c-a2a6-9615897eb271.jpg)
![3](https://user-images.githubusercontent.com/106807250/212663422-93b08108-766f-4a0d-adeb-38aa0d19238b.jpg)


9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

Необходимо было добавить владельца сокета в telegraf docker-compose.yml.

```
vagrant@vagrant:~/sandbox$ stat -c '%g' /var/run/docker.sock
997

user telegraf:997
```

Изменил контейнер telegraf в docker-compose.yml.

```
  telegraf:
    # Full tag list: https://hub.docker.com/r/library/telegraf/tags/
    build:
      context: ./images/telegraf/
      dockerfile: ./${TYPE}/Dockerfile
      args:
        TELEGRAF_TAG: ${TELEGRAF_TAG}
    image: "telegraf"
    privileged: true
    user: telegraf:997
    environment:
      HOSTNAME: "telegraf-getting-started"
    # Telegraf requires network access to InfluxDB
    links:
      - influxdb
    volumes:
      # Mount for telegraf configuration
      - ./telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      # Mount for Docker API access
      - /var/run/docker.sock:/var/run/docker.sock:Z
    depends_on:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```
Добавил докер метрики в telegraf.conf 

```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
  container_names = []
  timeout = "5s"
  perdevice = true
  total = false
```
![4](https://user-images.githubusercontent.com/106807250/212664542-d6a17984-8429-4e98-b3a8-ebfd0d9c6dee.jpg)


