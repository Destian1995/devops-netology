# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

Сначала нужно будет найти opid операции
```
db.currentOp(
        { "active" : true, 
		  "secs_running" : { "$gt" : 180 }
		  })
```
После того как появится результат выполнить следующую команду:
```
db.killOp(opid который нашелся по результату)
```

- Вариант решения проблемы:
```
1. Понадобится метод maxTimeMS() для установки предела времени исполнения операций 
2. Потребуется Database Profiler, для того чтобы отловить медленные операции.
3. Провести анализ плана выполнения запроса через explain("executionStats")
4. Попробовать оптимизировать: добавить/удалить индексы, настроить шардинг.
```
## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

```
Память забилась из-за того что срок действия ключей реплик не истекает, они ожидают истечения срока действия ключей мастеров.
В итоге истекшие ключи не удаляются. Redis заблокировал операции записи потому что процент истекших ключей превысил 25%.
"если в базе данных есть много-много ключей, истекающих в одну и ту же секунду, и 
они составляют не менее 25% от текущей совокупности ключей с истекающим набором, 
Redis может заблокировать, чтобы процент ключей ниже 25% уже истек."
```
 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```


Как вы думаете, почему это начало происходить и как локализовать проблему?
```
Нашел вот такую удобную статью https://dev.mysql.com/doc/refman/8.0/en/error-lost-connection.html
1. Приходим к выводу что проблема возникает, когда миллионы строк отправляются как часть одного или нескольких запросов. 
нужно увеличить параметр net_read_timeout с 30 секунд по умолчанию до 60 секунд или дольше.
2. Так же проблемы могут быть из-за нашего соединения в этом случае надо параметр connect_timeout увеличить на несколько секунд.
3. Иногда необходимо увеличить параметр max_allowed_packet, это нужно делать в том случае если возникает ER_NET_PACKET_TOO_LARGE
это происходит из-за превышение размера сообщения/запроса размера буфера max_allowed_packet
```

Какие пути решения данной проблемы вы можете предложить?

```
На сервере: Увеличение следующих значений wait_timeout, max_allowed_packet, net_write_timeout и net_read_timeout.
На стороне клиента: увеличить wait_timeout, производить pool_pre_ping. 
При исчезновении ошибки продиагностировать пороговые значения изменённых параметров при которых приложение работает стабильно, 
т.к. простое увеличение данных параметров может повлиять на работу приложений в целом.
```

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

```
Postgree не хватает памяти
Случается, что у ОС нет свободной памяти, но она закрепляет память за процессом, и когда процессу она нужна, 
ОС выделяет ее, если может. 
Минус в том, что иногда ОС резервирует память, но в нужный момент свободной памяти нет,
и происходит сбой системы. OOM играет важную роль в этом сценарии и завершает процессы, 
чтобы уберечь ядро от паники. Когда принудительно завершается процесс PostgreSQL, в логе появляется сообщение:
Out of Memory: Killed process 12345 (postgres).
```
Как бы вы решили данную проблему?


```
Добавить ресурсов на сервер(RAM), либо настроить подкачку.
Попробовать провести хаускиппинг и убрать мусорные приложения, чтобы высвободить больше ресурсов.


Провести настройку параметров PostgreSQL:

max_connections
Стоит уменьшить число подключений max_connections и организовать внешний пул соединений.

shared_buffer
Оптимальное число shared_buffers зависит от многих факторов, нужно учесть количество оперативной памяти компьютера, 
размер базы данных, число соединений и сложность запросов.

work_mem 
Установка этого параметра глобально может привести к очень высокому использованию памяти. 
Поэтому настоятельно рекомендуется изменить его на уровне сеанса.


effective_cache_size
Здесь нужно будет подбирать потмиальный параметр так как  если значение этого параметра установлено слишком низким, 
планировщик запросов может принять решение не использовать некоторые индексы, даже если они будут полезны. 
Поэтому установка большого значения всегда имеет смысл.

maintenance_work_mem
Размер выделяемой под эти операции памяти должен быть сравним с физическим размером самого большого индекса на диске. 
Как и в случае work_mem эта переменная может быть установлена прямо во время выполнения запроса.


Пример конфигурации:

# nano postgresql.conf

shared_buffers = 2GB                    # ~ 1/8 RAM and for Linux kernel.shmmax=4294967296 (1/4 of RAM)
work_mem = 128MB                        # ~ 1/20 RAM
maintenance_work_mem = 1GB              # ~ 1/4 RAM
effective_cache_size = 4GB              # ~ 2/3 RAM
```
---